{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation of cell nucleii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional ( I like QT Graphs so i can zoom and i think %matplotlib widget sucks!)\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Data comes from the git repo through [git lfs](https://git-lfs.github.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1040, 1408, 3)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "for imagePath in Path(\"./data\").glob(\"*.png\"):\n",
    "    image = cv2.imread(str(imagePath))\n",
    "    if image.size > 0:\n",
    "        images.append(image)\n",
    "    else:\n",
    "        print(f\"Failed reading image {imagePath}\")\n",
    "\n",
    "images = np.stack(images)\n",
    "N = len(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colPlot(images, **kwargs):\n",
    "    fig, axs = plt.subplots(1,len(images))\n",
    "\n",
    "    for im, ax in zip(images, axs):\n",
    "        if im.ndim > 2: # if color\n",
    "            ax.imshow(im[...,::-1]) # opencv is BGR\n",
    "        else:\n",
    "            ax.imshow(im, **kwargs)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "def multiRowPlot(images, titles, nrows, ncols, **kwargs):\n",
    "    fig, axs = plt.subplots(nrows, ncols, sharey=\"col\", sharex=\"col\")\n",
    "\n",
    "    for i, (im, title, ax) in enumerate(zip(images, titles, axs.flatten())):\n",
    "        ax.set_title(title)\n",
    "        ax.imshow(im, **kwargs)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "def imageTitles(pattern):\n",
    "    return [pattern.format(i=i) for i in range(1, N+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "First we analyse the channels of the image and pick the best way to \"grayscale\" it.\n",
    "\n",
    "The red channel is a highliting of cell nuceii, and the G and B channels (equivalent) are the grayscale, monochromatic image from the microscope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all channels (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colPlot(images[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot red channel and R-B for comparrison\n",
    "\n",
    "* $I_R-I_B$ clearly shows nucleii with high contrast and no unwanted features.\n",
    "* $I_R$ shows more detail for other parts of the cell. But that detail introduces unwanted features that don't have a very high contrast with nucleii\n",
    "\n",
    "**Use $I_f=I_R-I_B$ for segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the R channel\n",
    "R = images[...,2] \n",
    "\n",
    "# the R-B difference image\n",
    "diffRB = images[...,2] - images[...,0]\n",
    "\n",
    "# For plotting\n",
    "imPlots = chain(R, diffRB)\n",
    "imTitles = chain(imageTitles(\"$I_{{ {i}R }}$\"),\n",
    "        imageTitles(\"$I_{{ {i}R }} - I_{{ {i}B }}$\"))\n",
    "\n",
    "multiRowPlot(imPlots, imTitles, nrows=2, ncols=N, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(images,diffRB):\n",
    "    fig, axs = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "    axs[0].imshow(a[...,0], cmap=\"gray\")\n",
    "    axs[1].imshow(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "We can also see in a log-histogram that $I_R-I_B$ has a more more distinct peak in its histogram, meaning higher contrast between backgrond and features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def histColPlot(images:np.array, hist_args:dict):\n",
    "    fig, axs = plt.subplots(2,len(images))\n",
    "    for i, (im, ax) in enumerate(zip(images, axs[0])):\n",
    "        ax.set_title(f\"Image {i+1}\")\n",
    "        ax.imshow(im, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i, (im, ax) in enumerate(zip(images, axs[1])):\n",
    "        ax.set_title(f\"Image {i+1} hist\")\n",
    "        ax.hist(im.flatten(), **hist_args)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 8 Axes>,\n",
       " array([[<AxesSubplot:title={'center':'Image 1'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4'}>],\n",
       "        [<AxesSubplot:title={'center':'Image 1 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4 hist'}>]], dtype=object))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(R, \n",
    "            hist_args=dict(bins=255,log=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 8 Axes>,\n",
       " array([[<AxesSubplot:title={'center':'Image 1'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4'}>],\n",
       "        [<AxesSubplot:title={'center':'Image 1 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4 hist'}>]], dtype=object))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(diffRB, \n",
    "            hist_args=dict(bins=255,log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine $I_f$\n",
    "\n",
    "$I_f$ is the grayscale image we'll use for segmentation. We do a linear stretching of the $I_R-I_B$ image so that $max(I_R-I_B)=255$ and $min(I_R-I_B)=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, '$I_f$ and Histograms')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useChannel = diffRB\n",
    "\n",
    "# np.max is calculated over ALL images\n",
    "# This means e.g. we don't strech image 1 more than image 2\n",
    "minval = np.min(useChannel)\n",
    "If = (useChannel - minval) * 255.0 / (np.max(useChannel)-minval)\n",
    "\n",
    "If = If.astype(np.uint8)\n",
    "\n",
    "histColPlot(If, hist_args=dict(bins=255, log=True))\n",
    "plt.suptitle(\"$I_f$ and Histograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Thresholding\n",
    "\n",
    "We apply two thresholding techniques to segment the nucleii of cells using $I_f$.\n",
    "\n",
    "1. \"handmade\" threshold: from the histograms, we choose $T$ such that is isolates the background\n",
    "2. Otsu's technique: we use the opencv implementation of Otsu's thresholding to determine $T$\n",
    "\n",
    "We then extract the nucleii count and areas using `cv2.connectedComponents`, for result analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 8 Axes>,\n",
       " array([[<AxesSubplot:title={'center':'Image 1'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4'}>],\n",
       "        [<AxesSubplot:title={'center':'Image 1 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4 hist'}>]], dtype=object))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(If, hist_args=dict(bins=255, log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold: Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, '$I_f$ histograms and chosen Threshold')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feels like this is a good value:\n",
    "T = 40\n",
    "fig, axs = histColPlot(If, hist_args=dict(bins=255, log=False))\n",
    "\n",
    "for hist in axs[1]:\n",
    "    hist.axvline(T, color=\"r\", label=f\"{T=}\")\n",
    "    hist.legend()\n",
    "plt.suptitle(\"$I_f$ histograms and chosen Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshManual = 255* ( If > T )\n",
    "threshManual=threshManual.astype(np.uint8)\n",
    "\n",
    "imPlots = chain(If, threshManual)\n",
    "imTitles = chain(imageTitles(\"$I_f{{ {i} }}$\"), imageTitles(\"$T_{i}$\"))\n",
    "\n",
    "multiRowPlot(imPlots, imTitles, nrows=2, ncols=N, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold: Otsu`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<itertools.chain object at 0x7fba21af75e0>\n"
     ]
    }
   ],
   "source": [
    "threshOtsu = []\n",
    "threshOtsuVals = []\n",
    "for If_i in If:\n",
    "    ret, otsuThresh_i =  cv2.threshold(If_i, 127, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n",
    "    threshOtsu.append(otsuThresh_i)\n",
    "    threshOtsuVals.append(ret)\n",
    "\n",
    "threshOtsu=np.stack(threshOtsu, axis=0)\n",
    "\n",
    "imPlots = chain(images, threshManual, threshOtsu)\n",
    "imTitles = chain(imageTitles(\"$I_f{{ {i} }}$\"), \n",
    "    (\n",
    "      title + f\",{T=}\" \n",
    "      for title in imageTitles(\"$T_{i} Manual$\")\n",
    "    ),\n",
    "    ( title + f\", {T=}\"\n",
    "      for T, title \n",
    "      in zip(threshOtsuVals,imageTitles(\"$T_{i}$ Otsu\"))\n",
    "    ))\n",
    "\n",
    "print(imTitles)\n",
    "multiRowPlot(imPlots, imTitles, nrows=3, ncols=N, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "`ThreshManual` looks more consistant overall, with threshOtsu choosing a value that is slightly too high and leaves out part of some cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense because `Otsu` assumes a strong **bimodal distribution**, but the image has a very small foreground area. \n",
    "\n",
    "We can see this by calculating the percentage of pixels labeled as foreground by manual thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of foreground pixels (by image):\n",
      "[ 5060  7986 12246  7126]\n",
      "Percent of foreground pixels (by image):\n",
      "0.35%, 0.55%, 0.84%, 0.49%\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of foreground pixels (by image):\")\n",
    "print(np.count_nonzero(threshManual, axis=(1,2)))\n",
    "print(\"Percent of foreground pixels (by image):\")\n",
    "percents = np.round(np.count_nonzero(threshManual, axis=(1,2))/threshManual[0].size * 100, 2)\n",
    "print(\", \".join([f\"{p}%\" for p in percents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We picked this threshold:\n",
    "thresh = threshManual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get connected areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 8\n",
    "areas = []\n",
    "for image in thresh:\n",
    "    n_labels, labels =  cv2.connectedComponents(image, None, conn)\n",
    "\n",
    "    # count number of pixels in each connected component\n",
    "    # print(np.array([labels==i for i in range(n_labels)]).shape)\n",
    "    area = np.count_nonzero([labels==i for i in range(n_labels)], axis=(1,2))\n",
    "\n",
    "    # First item is background label\n",
    "    area = area[1:]\n",
    "\n",
    "    areas.append(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are a lot of areas with 1 or 2 pixels. \n",
    "    These are likely noise.\n",
    "\n",
    "    We'll calculate stats including them first, but later we'll try filtering out areas that equal 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 areas:\n",
      "[497   1   1 647 613   1   4  52   1 427  26   1  17   1   4   1   1   1\n",
      "   4   2   2   1   1   5   1   1 679   1   1   1   1   1 296 265 964   1\n",
      "  19 463   1   1  38   9   1   1   4]\n",
      "Image 2 areas:\n",
      "[ 587    1    1   44    9    1    7    1    7    6    1  583    1    1\n",
      "  373    3  493    1  623    1    1  694  663  802  610    1  487    1\n",
      " 1222  760    1]\n",
      "Image 3 areas:\n",
      "[ 937 1768 1175  718   15    1    1    1   10    1    1   22    1    1\n",
      "   21    1    1    3    5    1    2    7   36    1    7    1    1    1\n",
      "    1  732    1  689  659    1  514  573    1  708    1  531  655  575\n",
      "  735    1  498    1  630]\n",
      "Image 4 areas:\n",
      "[  1   1   1 481 598   1 945 669 583   1 860 610  11   3  59   1 440 776\n",
      " 379   1 705]\n"
     ]
    }
   ],
   "source": [
    "for i, area in enumerate(areas):\n",
    "    print(f\"Image {i+1} areas:\")\n",
    "    print(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats\n",
    "\n",
    "**Original** \n",
    "* We see there are a lot of 1-pixel areas (over 25% for some images, over 50% for image 1) .\n",
    "* Maybe because of this, the mean area for the first image is much smaller\n",
    "* The biggest nucleus is in image 3, which also has the highest mean size. But the median size of cells is higher on image4\n",
    "\n",
    "**With minimum area**\n",
    "* Now the mean size of images is more similar, with images 3 and 4 having the bigger cells\n",
    "* Standard deviation is very high, so cells are varying a lot in size.\n",
    "* We see this on the quartiles, with 20% of cells being smaller than 50 pixels on all images but image 4\n",
    "\n",
    "**Comparison with manual count**\n",
    "* Manual count is more similar to the minimum area values. \n",
    "* But either way these counts are different from the manual count. Mainly because of \"close-together\" nucleii being counted as only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(areas):\n",
    "    dfs = [pd.DataFrame(data={f\"image{i+1}\":area}) for i, area in enumerate(areas)]\n",
    "    print(pd.concat([df.describe().transpose().round(2) for df in dfs]))\n",
    "\n",
    "def get_areas_and_print_stats(images):\n",
    "    areas = []\n",
    "    for i, image in enumerate(images):\n",
    "        n_labels, labels =  cv2.connectedComponents(image, None, conn)\n",
    "        # count number of pixels in each connected component\n",
    "        # print(np.array([labels==i for i in range(n_labels)]).shape)\n",
    "        area = np.count_nonzero([labels==i for i in range(n_labels)], axis=(1,2))\n",
    "        # First item is background label\n",
    "        area = area[1:]\n",
    "        areas.append(area)\n",
    "    \n",
    "    print_stats(areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ALL\n",
      "        count    mean     std  min  25%    50%    75%     max\n",
      "image1   45.0  112.44  234.66  1.0  1.0    1.0   26.0   964.0\n",
      "image2   31.0  257.61  348.53  1.0  1.0    7.0  585.0  1222.0\n",
      "image3   47.0  260.55  403.17  1.0  1.0    5.0  574.0  1768.0\n",
      "image4   21.0  339.33  346.63  1.0  1.0  379.0  610.0   945.0\n",
      "====== Areas > min_area=5\n",
      "        count    mean     std   min    25%    50%    75%     max\n",
      "image1   15.0  334.13  306.73   9.0   32.0  296.0  555.0   964.0\n",
      "image2   17.0  468.82  350.44   6.0   44.0  583.0  663.0  1222.0\n",
      "image3   23.0  531.09  435.93   7.0   29.0  575.0  713.0  1768.0\n",
      "image4   13.0  547.38  277.79  11.0  440.0  598.0  705.0   945.0\n"
     ]
    }
   ],
   "source": [
    "print(\"====== ALL\")\n",
    "print_stats(areas)\n",
    "\n",
    "min_area=5\n",
    "print(f\"====== Areas > {min_area=}\")\n",
    "print_stats([a[a>min_area] for a in areas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient\n",
    "(need to study this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients=[]\n",
    "for If_i in If:\n",
    "    ddepth = cv2.CV_32F\n",
    "    dx = cv2.Sobel(If_i, ddepth, 1, 0)\n",
    "    dy = cv2.Sobel(If_i, ddepth, 0, 1)\n",
    "\n",
    "    gradients.append(np.sqrt(dx**2+dy**2))\n",
    "gradients=np.stack(gradients,axis=0)\n",
    "\n",
    "multiRowPlot(\n",
    "    chain(If, gradients),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ | \\\\Delta I_{{ f{i} }} | $\")),\n",
    "    2,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3))\n",
    "markers = [cv2.morphologyEx(Thresh_i, cv2.MORPH_OPEN, kernel) for Thresh_i in thresh]\n",
    "markers = [cv2.erode(m,  kernel) for m in markers]\n",
    "markers = np.stack(markers, axis=0)\n",
    "\n",
    "plt_images = chain(thresh, markers)\n",
    "plt_titles = chain(imageTitles(\"thresh\"), imageTitles(\"marker\"))\n",
    "multiRowPlot(plt_images , plt_titles , 2, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = gradients*255/gradients.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "watersheds=[]\n",
    "for m, grad in zip(markers, gradients):\n",
    "    conn = 8\n",
    "    n_labels, labels =  cv2.connectedComponents(m, None, conn)\n",
    "    im = np.stack([grad,grad,grad], axis=-1).astype(np.uint8)\n",
    "    out = cv2.watershed(im, m.astype(np.int32))\n",
    "    watersheds.append(out)\n",
    "\n",
    "\n",
    "multiRowPlot(\n",
    "    chain(If, watersheds),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"watershed {{ f{i} }}\")),\n",
    "    2,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51e85f04e04be4d88eed80c0e07765bbdfe0d9abe501b20be23dd8c1d7c4662d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
