{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de implementação 1: Segmentation of cell nucleii\n",
    "\n",
    "## Disciplina: Fundamentos de Visão Computacional\n",
    "### Alunos\n",
    "#### João Vitor Rodrigues - 00243705\n",
    "#### Pedro Sidra Freitas  - 00262537"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from IPython.display import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional ( I like QT Graphs so i can zoom and i think %matplotlib widget sucks!)\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data\n",
    "\n",
    "Data comes from the git repo through [git lfs](https://git-lfs.github.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1040, 1408, 3)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "for imagePath in Path(\"./data\").glob(\"*.png\"):\n",
    "    image = cv2.imread(str(imagePath))\n",
    "    if image.size > 0:\n",
    "        images.append(image)\n",
    "    else:\n",
    "        print(f\"Failed reading image {imagePath}\")\n",
    "\n",
    "images = np.stack(images)\n",
    "N = len(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximized=True\n",
    "def colPlot(images, **kwargs):\n",
    "    fig, axs = plt.subplots(1,len(images))\n",
    "\n",
    "    for im, ax in zip(images, axs):\n",
    "        if im.ndim > 2: # if color\n",
    "            ax.imshow(im[...,::-1]) # opencv is BGR\n",
    "        else:\n",
    "            ax.imshow(im, **kwargs)\n",
    "    \n",
    "    if maximized:\n",
    "        figManager = plt.get_current_fig_manager()\n",
    "        figManager.window.showMaximized()\n",
    "    fig.tight_layout()\n",
    "\n",
    "def multiRowPlot(images, titles, nrows, ncols, **kwargs):\n",
    "    fig, axs = plt.subplots(nrows, ncols, sharey=\"col\", sharex=\"col\")\n",
    "\n",
    "    for i, (im, title, ax) in enumerate(zip(images, titles, axs.flatten())):\n",
    "        ax.set_title(title)\n",
    "        ax.imshow(im, **kwargs)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "\n",
    "    if maximized:\n",
    "        figManager = plt.get_current_fig_manager()\n",
    "        figManager.window.showMaximized()\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "def imageTitles(pattern):\n",
    "    return [pattern.format(i=i) for i in range(1, N+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "First we analyse the channels of the image and pick the best way to \"grayscale\" it.\n",
    "\n",
    "The red channel is a highliting of cell nuceii, and the G and B channels (equivalent) are the grayscale, monochromatic image from the microscope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all channels (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colPlot(images[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot red channel and R-B for comparrison\n",
    "\n",
    "* $I_R-I_B$ clearly shows nucleii with high contrast and no unwanted features.\n",
    "* $I_R$ shows more detail for other parts of the cell. But that detail introduces unwanted features that don't have a very high contrast with nucleii\n",
    "\n",
    "**Use $I_f=I_R-I_B$ for segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the R channel\n",
    "R = images[...,2] \n",
    "\n",
    "# the R-B difference image\n",
    "diffRB = images[...,2] - images[...,0]\n",
    "\n",
    "# For plotting\n",
    "imPlots = chain(R, diffRB)\n",
    "imTitles = chain(imageTitles(\"$I_{{ {i}R }}$\"),\n",
    "        imageTitles(\"$I_{{ {i}R }} - I_{{ {i}B }}$\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRowPlot(imPlots, imTitles, nrows=2, ncols=N, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison between: **Ir** and **Ir-Ib**\n",
    "\n",
    "<img src=\"data/analysis/Ir___diff_Ir_Ib.png\" width=1000 height=800 align=\"center\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoomed comparaison between: **Ir** and **Ir-Ib**\n",
    "\n",
    "<img src=\"data/analysis/Ir___diff_Ir_Ib_Zoomed.png\" width=1000 height=800 align=\"center\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(images,diffRB):\n",
    "    fig, axs = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "    axs[0].imshow(a[...,0], cmap=\"gray\")\n",
    "    axs[1].imshow(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoomed Cmap from **Ir-Ib**\n",
    "\n",
    "<img src=\"data/analysis/diff_Ir_Ib_Zoomed_cmap.png\" width=1000 height=700 align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "We can also see in a log-histogram that $I_R-I_B$ has a more more distinct peak in its histogram, meaning higher contrast between backgrond and features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def histColPlot(images:np.array, hist_args:dict):\n",
    "    fig, axs = plt.subplots(2,len(images))\n",
    "    for i, (im, ax) in enumerate(zip(images, axs[0])):\n",
    "        ax.set_title(f\"Image {i+1}\")\n",
    "        ax.imshow(im, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i, (im, ax) in enumerate(zip(images, axs[1])):\n",
    "        ax.set_title(f\"Image {i+1} hist\")\n",
    "        ax.hist(im.flatten(), **hist_args)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 8 Axes>,\n",
       " array([[<AxesSubplot:title={'center':'Image 1'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4'}>],\n",
       "        [<AxesSubplot:title={'center':'Image 1 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4 hist'}>]], dtype=object))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(R, \n",
    "            hist_args=dict(bins=255,log=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 8 Axes>,\n",
       " array([[<AxesSubplot:title={'center':'Image 1'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4'}>],\n",
       "        [<AxesSubplot:title={'center':'Image 1 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4 hist'}>]], dtype=object))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(diffRB, \n",
    "            hist_args=dict(bins=255,log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram comparaison : **Red Channel** and **Ir-Ib** \n",
    "\n",
    "\n",
    "<img src=\"data/analysis/Hist_Red.png\" width=1200 height=900 align=\"center\" />\n",
    "\n",
    "<img src=\"data/analysis/Hist_diff_Ir_Ib.png\" width=1200 height=900 align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine $I_f$\n",
    "\n",
    "$I_f$ is the grayscale image we'll use for segmentation. We do a linear stretching of the $I_R-I_B$ image so that $max(I_R-I_B)=255$ and $min(I_R-I_B)=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "useChannel = diffRB\n",
    "\n",
    "# np.max is calculated over ALL images\n",
    "# This means e.g. we don't strech image 1 more than image 2\n",
    "minval = np.min(useChannel)\n",
    "If = (useChannel - minval) * 255.0 / (np.max(useChannel)-minval)\n",
    "\n",
    "If = If.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, '$I_f$ and Histograms')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(If, hist_args=dict(bins=255, log=True))\n",
    "plt.suptitle(\"$I_f$ and Histograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If** stretched histogram\n",
    "\n",
    "<img src=\"data/analysis/Hist_If.png\" width=1200 height=900 align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Thresholding\n",
    "\n",
    "We apply two thresholding techniques to segment the nucleii of cells using $I_f$.\n",
    "\n",
    "1. \"handmade\" threshold: from the histograms, we choose $T$ such that is isolates the background\n",
    "2. Otsu's technique: we use the opencv implementation of Otsu's thresholding to determine $T$\n",
    "\n",
    "We then extract the nucleii count and areas using `cv2.connectedComponents`, for result analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold: Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# for image in diffRB:\n",
    "#     data = image.flatten()\n",
    "    \n",
    "#     count, bins_count = np.histogram(data, bins='auto')\n",
    "\n",
    "#     # finding the PDF of the histogram using count values\n",
    "#     pdf = count / sum(count)\n",
    "    \n",
    "#     # using numpy np.cumsum to calculate the CDF\n",
    "#     # We can also find using the PDF values by looping and adding\n",
    "#     cdf = np.cumsum(pdf)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     Thresh_values = np.arange (5,40,5)\n",
    "#     no_of_colors= len(Thresh_values)\n",
    "#     colorT=[\"#00\"+''.join([random.choice('0123456789ABCDEF') for i in range(4)])\n",
    "#        for j in range(no_of_colors)]\n",
    "    \n",
    "#     # plotting PDF and CDF\n",
    "#     fig, axs = plt.subplots(1,1,sharex=True,sharey=True)\n",
    "#     plt.plot( pdf, color=\"green\", label=\"PDF\")\n",
    "#     plt.plot(bins_count[1:], cdf, label=\"CDF\")\n",
    "#     plt.xticks(np.arange(0,255,5))\n",
    "#     for i,T in enumerate(Thresh_values):\n",
    "#         plt.axvline(T, color='r', label=f\"{T=}\")\n",
    "#     plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the histograms, this seems like a good value for threshold\n",
    "T = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, '$I_f$ histograms and chosen Threshold')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = histColPlot(If, hist_args=dict(bins=255, log=True))\n",
    "\n",
    "for hist in axs[1]:\n",
    "    hist.axvline(T, color=\"r\", label=f\"{T=}\")\n",
    "    hist.legend()\n",
    "plt.suptitle(\"$I_f$ histograms and chosen Threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/analysis/Hist_If_Thresh30.png\" width=1200 height=900 align=\"center\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshManual = 255* ( If > T )\n",
    "threshManual=threshManual.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imPlots = chain(If, threshManual)\n",
    "imTitles = chain(imageTitles(\"$I_f{{ {i} }}$\"), imageTitles(\"$T_{i}$\"))\n",
    "\n",
    "multiRowPlot(imPlots, imTitles, nrows=2, ncols=N, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary image Zoomed\n",
    "\n",
    "<img src=\"data/analysis/If_Thresh_30_Zoomed.png\" width=1200 height=900 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold: Otsu`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshOtsu = []\n",
    "threshOtsuVals = []\n",
    "for If_i in If:\n",
    "    ret, otsuThresh_i =  cv2.threshold(If_i, 127, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n",
    "    threshOtsu.append(otsuThresh_i)\n",
    "    threshOtsuVals.append(ret)\n",
    "\n",
    "threshOtsu=np.stack(threshOtsu, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<itertools.chain object at 0x0000017CE60CC820>\n"
     ]
    }
   ],
   "source": [
    "imPlots = chain(If, threshManual, threshOtsu)\n",
    "imTitles = chain(imageTitles(\"$I_f{{ {i} }}$\"), \n",
    "    (\n",
    "      title + f\",{T=}\" \n",
    "      for title in imageTitles(\"$T_{i} Manual$\")\n",
    "    ),\n",
    "    ( title + f\", {T=}\"\n",
    "      for T, title \n",
    "      in zip(threshOtsuVals,imageTitles(\"$T_{i}$ Otsu\"))\n",
    "    ))\n",
    "\n",
    "print(imTitles)\n",
    "multiRowPlot(imPlots, imTitles, nrows=3, ncols=N, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoomed comparaison between **Manual Threshold** and **Otsu's**\n",
    "\n",
    "\n",
    "<img src=\"data/analysis/Thresh_manual-30_Otsu_Zoomed.png\" width=1200 height=900 align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "`ThreshManual` looks more consistant overall, with `threshOtsu` choosing a value that is slightly too high and leaves out part of some cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense because `Otsu` assumes a strong **bimodal distribution**, but the image has a very small foreground area. \n",
    "\n",
    "We can see this by calculating the percentage of pixels labeled as foreground by manual thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of foreground pixels (by image):\n",
      "[ 8772  6038 14083  8174]\n",
      "Percent of foreground pixels (by image):\n",
      "0.6%, 0.41%, 0.96%, 0.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of foreground pixels (by image):\")\n",
    "print(np.count_nonzero(threshManual, axis=(1,2)))\n",
    "print(\"Percent of foreground pixels (by image):\")\n",
    "percents = np.round(np.count_nonzero(threshManual, axis=(1,2))/threshManual[0].size * 100, 2)\n",
    "print(\", \".join([f\"{p}%\" for p in percents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We picked this threshold:\n",
    "thresh = threshManual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get connected areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 8\n",
    "areas = []\n",
    "for image in thresh:\n",
    "    n_labels, labels =  cv2.connectedComponents(image, None, conn)\n",
    "\n",
    "    # count number of pixels in each connected component\n",
    "    # print(np.array([labels==i for i in range(n_labels)]).shape)\n",
    "    area = np.count_nonzero([labels==i for i in range(n_labels)], axis=(1,2))\n",
    "\n",
    "    # First item is background label\n",
    "    area = area[1:]\n",
    "\n",
    "    areas.append(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are a lot of areas with 1 or 2 pixels. \n",
    "    These are likely noise.\n",
    "\n",
    "    We'll calculate stats including them first, but later we'll try filtering out areas that equal 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 areas:\n",
      "[   1  641    1    1    1    1   52    1   12    1   15   12    1    7\n",
      "    1    1  624    1    1  509    1    1  534    1  660    1    1  739\n",
      "  698  855    1  672    1    1  591    1 1284    1    1  803    1    1\n",
      "    1    1    1    2    1    1    1   11    1    1    2    1    5    3\n",
      "    1    1    2    1    1    1]\n",
      "Image 2 areas:\n",
      "[   1    1  604    1    1    1    1    1    1  698    1    1    1    1\n",
      "    1  671    1    1   76    1    1    3    1    8    3    1    1    1\n",
      "  482    3    2    1    1    5   10    1    2    3  137    1    1    1\n",
      "   13    2    1    2    1    1   11    1    1    1    1  739    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "  381    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1  376    1    1    1    1    1 1008    1    1    1    1\n",
      "    1    1    1    1    1    1    1   34  556    1    1    2    1    1\n",
      "    1   56    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1   30    1    2]\n",
      "Image 3 areas:\n",
      "[ 991 1879    1 1263  784   27    1  202    1    1    1    1    1   36\n",
      "    5    1  171    6    1    2    1    2   50    1    2    1    1    2\n",
      "    2    1    1    2  176   15    3    1    3    1    1    3    2    1\n",
      "    1    1    1    1  833    1    1  786  723    1  581  612    1  765\n",
      "    1    1  575  699  687  823    1  658    1  680    1    1]\n",
      "Image 4 areas:\n",
      "[   1    1    1    1  658  533    1 1026    1  709    1  706    1  908\n",
      "  664    1  316    1    2    1    1    1    1  532  819  535  752]\n"
     ]
    }
   ],
   "source": [
    "for i, area in enumerate(areas):\n",
    "    print(f\"Image {i+1} areas:\")\n",
    "    print(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats\n",
    "\n",
    "**Original** \n",
    "* We see there are a lot of 1-pixel areas (over 25% for some images, over 50% for image 1) .\n",
    "* Maybe because of this, the mean area for the first image is much smaller\n",
    "* The biggest nucleus is in image 3, which also has the highest mean size. But the median size of cells is higher on image4\n",
    "\n",
    "**With minimum area**\n",
    "* Now the mean size of images is more similar, with images 3 and 4 having the bigger cells\n",
    "* Standard deviation is very high, so cells are varying a lot in size.\n",
    "* We see this on the quartiles, with 20% of cells being smaller than 50 pixels on all images but image 4\n",
    "\n",
    "**Comparison with manual count**\n",
    "* Manual count is more similar to the minimum area values. \n",
    "* But either way these counts are different from the manual count. Mainly because of \"close-together\" nucleii being counted as only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(areas):\n",
    "    dfs = [pd.DataFrame(data={f\"image{i+1}\":area}) for i, area in enumerate(areas)]\n",
    "    print(pd.concat([df.describe().transpose().round(2) for df in dfs]))\n",
    "\n",
    "def get_areas_and_print_stats(images):\n",
    "    areas = []\n",
    "    for i, image in enumerate(images):\n",
    "        n_labels, labels =  cv2.connectedComponents(image, None, conn)\n",
    "        # count number of pixels in each connected component\n",
    "        # print(np.array([labels==i for i in range(n_labels)]).shape)\n",
    "        area = np.count_nonzero([labels==i for i in range(n_labels)], axis=(1,2))\n",
    "        # First item is background label\n",
    "        area = area[1:]\n",
    "        areas.append(area)\n",
    "    \n",
    "    print_stats(areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ALL\n",
      "        count    mean     std  min  25%  50%     75%     max\n",
      "image1   62.0  141.48  297.56  1.0  1.0  1.0   11.75  1284.0\n",
      "image2  148.0   40.80  153.78  1.0  1.0  1.0    1.00  1008.0\n",
      "image3   68.0  207.10  384.54  1.0  1.0  2.0  182.50  1879.0\n",
      "image4   27.0  302.74  365.17  1.0  1.0  1.0  661.00  1026.0\n",
      "====== Areas > min_area=5\n",
      "        count    mean     std    min     25%    50%     75%     max\n",
      "image1   18.0  484.39  377.20    7.0   24.25  607.5  691.50  1284.0\n",
      "image2   18.0  327.22  324.97    8.0   31.00  256.5  592.00  1008.0\n",
      "image3   24.0  584.25  448.75    6.0  174.75  669.0  784.50  1879.0\n",
      "image4   12.0  679.83  189.62  316.0  534.50  685.0  768.75  1026.0\n"
     ]
    }
   ],
   "source": [
    "print(\"====== ALL\")\n",
    "print_stats(areas)\n",
    "\n",
    "min_area=5\n",
    "print(f\"====== Areas > {min_area=}\")\n",
    "print_stats([a[a>min_area] for a in areas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients=[]\n",
    "for If_i in If:\n",
    "    ddepth = cv2.CV_32F\n",
    "    \n",
    "    dx = cv2.Sobel(If_i, ddepth, 1, 0)\n",
    "    dy = cv2.Sobel(If_i, ddepth, 0, 1)\n",
    "\n",
    "    gradients.append(np.sqrt(dx**2+dy**2))\n",
    "gradients=np.stack(gradients,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRowPlot(\n",
    "    chain(If, gradients),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ | \\\\Delta I_{{ f{i} }} | $\")),\n",
    "    2,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients from **If**\n",
    "\n",
    "<img src=\"data/analysis/Gradients_If_ThreshManual.png\" width=1400 height=1000 align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3))\n",
    "markers = [cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel) for m in thresh]\n",
    "markers = [cv2.erode(m,  kernel) for m in markers]\n",
    "markers = np.stack(markers, axis=0)\n",
    "\n",
    "# kernel = np.ones((35,35))\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(35,35))\n",
    "bgs = [~cv2.dilate(m,  kernel, iterations=3) for m in thresh]\n",
    "bgs = np.stack(bgs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_images = chain(thresh, markers, bgs)\n",
    "plt_titles = chain(imageTitles(\"thresh\"), imageTitles(\"marker\"), imageTitles(\"background\"))\n",
    "multiRowPlot(plt_images , plt_titles , 3, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markers and Backgrounds\n",
    "\n",
    "<img src=\"data/analysis/Marker_and_Background.png\" width=1600 height=1200 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = gradients*255/gradients.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import watershed\n",
    "\n",
    "watersheds=[]\n",
    "for m, bg, grad in zip(markers, bgs, gradients):\n",
    "    conn = 8\n",
    "    n_labels, labels =  cv2.connectedComponents(m, None, conn)\n",
    "\n",
    "    labels[bg>0] = labels.max() + 1\n",
    "    # plt.imshow(labels * 255 / labels.max())\n",
    "    out = watershed(grad, labels.astype(np.int32))\n",
    "    out[out==out.max()] = 0\n",
    "    watersheds.append(out)\n",
    "watersheds=np.stack(watersheds,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRowPlot(\n",
    "    chain(If, markers, watersheds>0),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$marker_{{ B{i} }}$\"), imageTitles(\"$watershed_{{ {i} }}$\")),\n",
    "    3,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoomed **Watershed**\n",
    "\n",
    "<img src=\"data/analysis/Watershed_Zoomed.png\" width=1600 height=1200 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ALL\n",
      "        count    mean     std  min  25%  50%     75%     max\n",
      "image1   62.0  141.48  297.56  1.0  1.0  1.0   11.75  1284.0\n",
      "image2  148.0   40.80  153.78  1.0  1.0  1.0    1.00  1008.0\n",
      "image3   68.0  207.10  384.54  1.0  1.0  2.0  182.50  1879.0\n",
      "image4   27.0  302.74  365.17  1.0  1.0  1.0  661.00  1026.0\n",
      "====== Areas > min_area=5\n",
      "        count    mean     std    min     25%    50%     75%     max\n",
      "image1   18.0  484.39  377.20    7.0   24.25  607.5  691.50  1284.0\n",
      "image2   18.0  327.22  324.97    8.0   31.00  256.5  592.00  1008.0\n",
      "image3   24.0  584.25  448.75    6.0  174.75  669.0  784.50  1879.0\n",
      "image4   12.0  679.83  189.62  316.0  534.50  685.0  768.75  1026.0\n",
      "====== watershed\n",
      "        count    mean     std    min     25%    50%    75%     max\n",
      "image1   17.0  454.29  326.54    5.0   28.00  574.0  601.0  1135.0\n",
      "image2   15.0  376.33  284.48    4.0   57.00  401.0  590.0   933.0\n",
      "image3   21.0  672.71  331.72   17.0  512.00  654.0  741.0  1723.0\n",
      "image4   12.0  659.67  140.01  438.0  565.75  646.5  705.0   969.0\n"
     ]
    }
   ],
   "source": [
    "print(\"====== ALL\")\n",
    "print_stats(areas)\n",
    "\n",
    "min_area=5\n",
    "print(f\"====== Areas > {min_area=}\")\n",
    "print_stats([a[a>min_area] for a in areas])\n",
    "print(f\"====== watershed\")\n",
    "get_areas_and_print_stats(255*(watersheds>0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement 1: different filters / morph ops\n",
    "\n",
    "(draft. just to play with median blur and morph ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered=[]\n",
    "for If_i in If:\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "    ddepth = cv2.CV_32F\n",
    "    \n",
    "    f = If_i\n",
    "    # f = cv2.medianBlur(f, ksize=7)\n",
    "\n",
    "    f = 255*(f > T)\n",
    "\n",
    "    f = cv2.morphologyEx(f.astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
    "    f = cv2.morphologyEx(f.astype(np.uint8), cv2.MORPH_OPEN, kernel)\n",
    "    # f = cv2.dilate(f.astype(np.uint8),  kernel, iterations=2)\n",
    "    filtered.append(f)\n",
    "    \n",
    "multiRowPlot(\n",
    "    chain(If, thresh, filtered),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ Thresh I_{{ f{i} }} $\"), imageTitles(\"$ Filter I_{{ f{i} }} $\")),\n",
    "    3,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoomed **Watershed** with different filters\n",
    "\n",
    "<img src=\"data/analysis/Watershed_Zoomed_Imp1.png\" width=1600 height=1200 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement 2: K-Means segmentation\n",
    "\n",
    "... Just a fancy threshold, doesn`t help much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=[]\n",
    "for If_i in If:\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    # Set flags (Just to avoid line break in the code)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    # Apply KMeans\n",
    "    compactness,labels,centers = cv2.kmeans(\n",
    "            If_i.ravel().astype(np.float32),\n",
    "            2,\n",
    "            None,\n",
    "            criteria,\n",
    "            10,\n",
    "            flags\n",
    "        )\n",
    "\n",
    "    km = If_i.copy()\n",
    "    km.flat[labels.ravel()==0] = 0\n",
    "    km.flat[labels.ravel()==1] = 1\n",
    "\n",
    "    kmeans.append(km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRowPlot(\n",
    "    chain(If, kmeans, thresh),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ KMeans ~I_{{ f{i} }} $\"), imageTitles(\"$ Thresh~I_{{ f{i} }} $\")),\n",
    "    3,\n",
    "    N\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoomed **Watershed**\n",
    "\n",
    "<img src=\"data/analysis/Watershed_Zoomed_Imp2.png\" width=1600 height=1200 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement 3: Filter image before thresholding\n",
    "\n",
    "Ok so this one looks better. Basically:\n",
    "\n",
    "* Filter $I_f$ using a median filter, since it seems to have a good amount of shot noise\n",
    "* Lower the threshold because now we don`t have too much noise\n",
    "* Skip the morphology operations on $I_b$ and simply use the original $I_b$ as markers for watershed\n",
    "* Use a \"Sure-Background\" marker for the watersheds. Obtain it from a large dilation of the union of foreground markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients=[]\n",
    "filts=[]\n",
    "for If_i in If:\n",
    "    ddepth = cv2.CV_32F\n",
    "    \n",
    "    filt=If_i\n",
    "    # filt = cv2.blur(filt, ksize=(3,3))\n",
    "    filt = cv2.medianBlur(filt, ksize=3)\n",
    "    filts.append(filt)\n",
    "    dx = cv2.Sobel(filt, ddepth, 1, 0)\n",
    "    dy = cv2.Sobel(filt, ddepth, 0, 1)\n",
    "\n",
    "    gradients.append(np.sqrt(dx**2+dy**2))\n",
    "\n",
    "gradients=np.stack(gradients,axis=0)\n",
    "filts=np.stack(filts,axis=0)\n",
    "\n",
    "T = 25\n",
    "\n",
    "thresh = 255*(filts > T).astype(np.uint8)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(35,35))\n",
    "bgs = [~cv2.dilate(m,  kernel, iterations=3) for m in thresh]\n",
    "bgs = np.stack(bgs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot filtered image, threshold, markers and background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRowPlot(\n",
    "    chain(If, filts, gradients),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ Filtered ~I_{{ f{i} }} $\"), imageTitles(\"$ Gradient~I_{{ f{i} }} $\")),\n",
    "    3,\n",
    "    N\n",
    "    )\n",
    "\n",
    "multiRowPlot(\n",
    "    chain(If, thresh, bgs),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ thrsh ~I_{{ f{i} }} $\"), imageTitles(\"$ bgs~I_{{ f{i} }} $\")),\n",
    "    3,\n",
    "    N\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients from improv 3\n",
    "\n",
    "<img src=\"data/analysis/Gradients_Imp3.png\" width=1400 height=1000 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background image\n",
    "\n",
    "\n",
    "<img src=\"data/analysis/Background_Imp3.png\" width=1400 height=1000 align= \"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calc watershed with filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "watersheds=[]\n",
    "for t, bg, grad in zip(thresh, bgs, gradients):\n",
    "    conn = 8\n",
    "\n",
    "    n_labels, labels =  cv2.connectedComponents(t, None, conn)\n",
    "\n",
    "    labels[bg>0] = labels.max() + 1\n",
    "    # plt.imshow(labels * 255 / labels.max())\n",
    "    out = watershed(grad, labels.astype(np.int32))\n",
    "    out[out==out.max()] = 0\n",
    "    watersheds.append(out)\n",
    "watersheds=np.stack(watersheds,axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result (image 1 has two new nucleii which wasn't detected before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRowPlot(\n",
    "    chain(If, thresh, watersheds>0),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$marker_{{ B{i} }}$\"), imageTitles(\"$watershed_{{ {i} }}$\")),\n",
    "    3,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoomed Watershed Improvement 3\n",
    "\n",
    "\n",
    "<img src=\"data/analysis/Watershed_Zoomed_Imp3.png\" width=1400 height=1000  align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison **Original Watershed** and **Improved Watershed**\n",
    "\n",
    "\n",
    "<img src=\"data/analysis/Watershed_Comp_Orig.png\" width=1000 height=800 align=\"center\"/>\n",
    "\n",
    "<img src=\"data/analysis/Watershed_Comp_Imp.png\" width=1000 height=800 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51e85f04e04be4d88eed80c0e07765bbdfe0d9abe501b20be23dd8c1d7c4662d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
