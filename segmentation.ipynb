{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation of cell nucleii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional ( I like QT Graphs so i can zoom and i think %matplotlib widget sucks!)\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Data comes from the git repo through [git lfs](https://git-lfs.github.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1040, 1408, 3)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "for imagePath in Path(\"./data\").glob(\"*.png\"):\n",
    "    image = cv2.imread(str(imagePath))\n",
    "    if image.size > 0:\n",
    "        images.append(image)\n",
    "    else:\n",
    "        print(f\"Failed reading image {imagePath}\")\n",
    "\n",
    "images = np.stack(images)\n",
    "N = len(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximized=True\n",
    "def colPlot(images, **kwargs):\n",
    "    fig, axs = plt.subplots(1,len(images))\n",
    "\n",
    "    for im, ax in zip(images, axs):\n",
    "        if im.ndim > 2: # if color\n",
    "            ax.imshow(im[...,::-1]) # opencv is BGR\n",
    "        else:\n",
    "            ax.imshow(im, **kwargs)\n",
    "    \n",
    "    if maximized:\n",
    "        figManager = plt.get_current_fig_manager()\n",
    "        figManager.window.showMaximized()\n",
    "    fig.tight_layout()\n",
    "\n",
    "def multiRowPlot(images, titles, nrows, ncols, **kwargs):\n",
    "    fig, axs = plt.subplots(nrows, ncols, sharey=\"col\", sharex=\"col\")\n",
    "\n",
    "    for i, (im, title, ax) in enumerate(zip(images, titles, axs.flatten())):\n",
    "        ax.set_title(title)\n",
    "        ax.imshow(im, **kwargs)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "\n",
    "    if maximized:\n",
    "        figManager = plt.get_current_fig_manager()\n",
    "        figManager.window.showMaximized()\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "def imageTitles(pattern):\n",
    "    return [pattern.format(i=i) for i in range(1, N+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "First we analyse the channels of the image and pick the best way to \"grayscale\" it.\n",
    "\n",
    "The red channel is a highliting of cell nuceii, and the G and B channels (equivalent) are the grayscale, monochromatic image from the microscope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all channels (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colPlot(images[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot red channel and R-B for comparrison\n",
    "\n",
    "* $I_R-I_B$ clearly shows nucleii with high contrast and no unwanted features.\n",
    "* $I_R$ shows more detail for other parts of the cell. But that detail introduces unwanted features that don't have a very high contrast with nucleii\n",
    "\n",
    "**Use $I_f=I_R-I_B$ for segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the R channel\n",
    "R = images[...,2] \n",
    "\n",
    "# the R-B difference image\n",
    "diffRB = images[...,2] - images[...,0]\n",
    "\n",
    "# For plotting\n",
    "imPlots = chain(R, diffRB)\n",
    "imTitles = chain(imageTitles(\"$I_{{ {i}R }}$\"),\n",
    "        imageTitles(\"$I_{{ {i}R }} - I_{{ {i}B }}$\"))\n",
    "\n",
    "multiRowPlot(imPlots, imTitles, nrows=2, ncols=N, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(images,diffRB):\n",
    "    fig, axs = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "    axs[0].imshow(a[...,0], cmap=\"gray\")\n",
    "    axs[1].imshow(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "We can also see in a log-histogram that $I_R-I_B$ has a more more distinct peak in its histogram, meaning higher contrast between backgrond and features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def histColPlot(images:np.array, hist_args:dict):\n",
    "    fig, axs = plt.subplots(2,len(images))\n",
    "    for i, (im, ax) in enumerate(zip(images, axs[0])):\n",
    "        ax.set_title(f\"Image {i+1}\")\n",
    "        ax.imshow(im, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i, (im, ax) in enumerate(zip(images, axs[1])):\n",
    "        ax.set_title(f\"Image {i+1} hist\")\n",
    "        ax.hist(im.flatten(), **hist_args)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 8 Axes>,\n",
       " array([[<AxesSubplot:title={'center':'Image 1'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4'}>],\n",
       "        [<AxesSubplot:title={'center':'Image 1 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4 hist'}>]], dtype=object))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(R, \n",
    "            hist_args=dict(bins=255,log=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 8 Axes>,\n",
       " array([[<AxesSubplot:title={'center':'Image 1'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4'}>],\n",
       "        [<AxesSubplot:title={'center':'Image 1 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4 hist'}>]], dtype=object))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(diffRB, \n",
    "            hist_args=dict(bins=255,log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine $I_f$\n",
    "\n",
    "$I_f$ is the grayscale image we'll use for segmentation. We do a linear stretching of the $I_R-I_B$ image so that $max(I_R-I_B)=255$ and $min(I_R-I_B)=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, '$I_f$ and Histograms')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useChannel = diffRB\n",
    "\n",
    "# np.max is calculated over ALL images\n",
    "# This means e.g. we don't strech image 1 more than image 2\n",
    "minval = np.min(useChannel)\n",
    "If = (useChannel - minval) * 255.0 / (np.max(useChannel)-minval)\n",
    "\n",
    "If = If.astype(np.uint8)\n",
    "\n",
    "histColPlot(If, hist_args=dict(bins=255, log=True))\n",
    "plt.suptitle(\"$I_f$ and Histograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Thresholding\n",
    "\n",
    "We apply two thresholding techniques to segment the nucleii of cells using $I_f$.\n",
    "\n",
    "1. \"handmade\" threshold: from the histograms, we choose $T$ such that is isolates the background\n",
    "2. Otsu's technique: we use the opencv implementation of Otsu's thresholding to determine $T$\n",
    "\n",
    "We then extract the nucleii count and areas using `cv2.connectedComponents`, for result analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 8 Axes>,\n",
       " array([[<AxesSubplot:title={'center':'Image 1'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4'}>],\n",
       "        [<AxesSubplot:title={'center':'Image 1 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 2 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 3 hist'}>,\n",
       "         <AxesSubplot:title={'center':'Image 4 hist'}>]], dtype=object))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histColPlot(If, hist_args=dict(bins=255, log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold: Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feels like this is a good value:\n",
    "T = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, '$I_f$ histograms and chosen Threshold')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = histColPlot(If, hist_args=dict(bins=255, log=True))\n",
    "\n",
    "for hist in axs[1]:\n",
    "    hist.axvline(T, color=\"r\", label=f\"{T=}\")\n",
    "    hist.legend()\n",
    "plt.suptitle(\"$I_f$ histograms and chosen Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshManual = 255* ( If > T )\n",
    "threshManual=threshManual.astype(np.uint8)\n",
    "\n",
    "imPlots = chain(If, threshManual)\n",
    "imTitles = chain(imageTitles(\"$I_f{{ {i} }}$\"), imageTitles(\"$T_{i}$\"))\n",
    "\n",
    "multiRowPlot(imPlots, imTitles, nrows=2, ncols=N, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold: Otsu`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<itertools.chain object at 0x7f1d4f90ef70>\n"
     ]
    }
   ],
   "source": [
    "threshOtsu = []\n",
    "threshOtsuVals = []\n",
    "for If_i in If:\n",
    "    ret, otsuThresh_i =  cv2.threshold(If_i, 127, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n",
    "    threshOtsu.append(otsuThresh_i)\n",
    "    threshOtsuVals.append(ret)\n",
    "\n",
    "threshOtsu=np.stack(threshOtsu, axis=0)\n",
    "\n",
    "imPlots = chain(If, threshManual, threshOtsu)\n",
    "imTitles = chain(imageTitles(\"$I_f{{ {i} }}$\"), \n",
    "    (\n",
    "      title + f\",{T=}\" \n",
    "      for title in imageTitles(\"$T_{i} Manual$\")\n",
    "    ),\n",
    "    ( title + f\", {T=}\"\n",
    "      for T, title \n",
    "      in zip(threshOtsuVals,imageTitles(\"$T_{i}$ Otsu\"))\n",
    "    ))\n",
    "\n",
    "print(imTitles)\n",
    "multiRowPlot(imPlots, imTitles, nrows=3, ncols=N, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "`ThreshManual` looks more consistant overall, with `threshOtsu` choosing a value that is slightly too high and leaves out part of some cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense because `Otsu` assumes a strong **bimodal distribution**, but the image has a very small foreground area. \n",
    "\n",
    "We can see this by calculating the percentage of pixels labeled as foreground by manual thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of foreground pixels (by image):\n",
      "[ 5519  8306 13064  7621]\n",
      "Percent of foreground pixels (by image):\n",
      "0.38%, 0.57%, 0.89%, 0.52%\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of foreground pixels (by image):\")\n",
    "print(np.count_nonzero(threshManual, axis=(1,2)))\n",
    "print(\"Percent of foreground pixels (by image):\")\n",
    "percents = np.round(np.count_nonzero(threshManual, axis=(1,2))/threshManual[0].size * 100, 2)\n",
    "print(\", \".join([f\"{p}%\" for p in percents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We picked this threshold:\n",
    "thresh = threshManual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get connected areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 8\n",
    "areas = []\n",
    "for image in thresh:\n",
    "    n_labels, labels =  cv2.connectedComponents(image, None, conn)\n",
    "\n",
    "    # count number of pixels in each connected component\n",
    "    # print(np.array([labels==i for i in range(n_labels)]).shape)\n",
    "    area = np.count_nonzero([labels==i for i in range(n_labels)], axis=(1,2))\n",
    "\n",
    "    # First item is background label\n",
    "    area = area[1:]\n",
    "\n",
    "    areas.append(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are a lot of areas with 1 or 2 pixels. \n",
    "    These are likely noise.\n",
    "\n",
    "    We'll calculate stats including them first, but later we'll try filtering out areas that equal 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 areas:\n",
      "[568   1 674 641   1   5  58   1   2 451   1   1   1   2  27   3  26   8\n",
      "   1   1  24   1   1   1   1   8   1   1 710   1   1   1   1   1 346   1\n",
      "   1 321 990   1   1   1   1  29 516   1   1   1   1  49   1   1   1   1\n",
      "   1  25   1   1]\n",
      "Image 2 areas:\n",
      "[ 612    1    1   46    9    1   10    8    1    6    1  601    1    1\n",
      "  447  515    1  642    1    1  704  678  820  639    1  532 1247  772\n",
      "    1    1    1    2    1    1]\n",
      "Image 3 areas:\n",
      "[ 963 1821 1216  761    1   20    1    1   42    2    1    2    3    8\n",
      "   41    1    2    2    3    2    1    1   20    2    1   26    1    3\n",
      "    1    8    2    7    3    1    1    1    1    1    1    1    1    2\n",
      "   18    1    1    1   56    7    2    1    1    1    1  779    1  736\n",
      "  690    1  554  591    1  737    1  552  679  634  786    1  593  658\n",
      "    1]\n",
      "Image 4 areas:\n",
      "[  1   1   1 619 504   1 980   1 690   1 663   1 886 636  15   1   1  17\n",
      "   1   2   1   1  78   1   1   4   1   1   1   1   1   1 501 799 475 732]\n"
     ]
    }
   ],
   "source": [
    "for i, area in enumerate(areas):\n",
    "    print(f\"Image {i+1} areas:\")\n",
    "    print(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats\n",
    "\n",
    "**Original** \n",
    "* We see there are a lot of 1-pixel areas (over 25% for some images, over 50% for image 1) .\n",
    "* Maybe because of this, the mean area for the first image is much smaller\n",
    "* The biggest nucleus is in image 3, which also has the highest mean size. But the median size of cells is higher on image4\n",
    "\n",
    "**With minimum area**\n",
    "* Now the mean size of images is more similar, with images 3 and 4 having the bigger cells\n",
    "* Standard deviation is very high, so cells are varying a lot in size.\n",
    "* We see this on the quartiles, with 20% of cells being smaller than 50 pixels on all images but image 4\n",
    "\n",
    "**Comparison with manual count**\n",
    "* Manual count is more similar to the minimum area values. \n",
    "* But either way these counts are different from the manual count. Mainly because of \"close-together\" nucleii being counted as only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(areas):\n",
    "    dfs = [pd.DataFrame(data={f\"image{i+1}\":area}) for i, area in enumerate(areas)]\n",
    "    print(pd.concat([df.describe().transpose().round(2) for df in dfs]))\n",
    "\n",
    "def get_areas_and_print_stats(images):\n",
    "    areas = []\n",
    "    for i, image in enumerate(images):\n",
    "        n_labels, labels =  cv2.connectedComponents(image, None, conn)\n",
    "        # count number of pixels in each connected component\n",
    "        # print(np.array([labels==i for i in range(n_labels)]).shape)\n",
    "        area = np.count_nonzero([labels==i for i in range(n_labels)], axis=(1,2))\n",
    "        # First item is background label\n",
    "        area = area[1:]\n",
    "        areas.append(area)\n",
    "    \n",
    "    print_stats(areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ALL\n",
      "        count    mean     std  min  25%  50%     75%     max\n",
      "image1   58.0   95.16  223.55  1.0  1.0  1.0   24.75   990.0\n",
      "image2   34.0  244.29  350.60  1.0  1.0  4.0  583.75  1247.0\n",
      "image3   71.0  184.00  364.50  1.0  1.0  2.0   41.50  1821.0\n",
      "image4   36.0  211.69  327.19  1.0  1.0  1.0  501.75   980.0\n",
      "====== Areas > min_area=5\n",
      "        count    mean     std   min     25%    50%    75%     max\n",
      "image1   18.0  303.94  317.24   8.0   26.25  189.5  555.0   990.0\n",
      "image2   17.0  487.53  357.49   6.0   46.00  601.0  678.0  1247.0\n",
      "image3   27.0  481.59  457.49   7.0   23.00  591.0  736.5  1821.0\n",
      "image4   14.0  542.50  308.83  15.0  481.50  627.5  721.5   980.0\n"
     ]
    }
   ],
   "source": [
    "print(\"====== ALL\")\n",
    "print_stats(areas)\n",
    "\n",
    "min_area=5\n",
    "print(f\"====== Areas > {min_area=}\")\n",
    "print_stats([a[a>min_area] for a in areas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient\n",
    "(need to study this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients=[]\n",
    "for If_i in If:\n",
    "    ddepth = cv2.CV_32F\n",
    "    \n",
    "    dx = cv2.Sobel(If_i, ddepth, 1, 0)\n",
    "    dy = cv2.Sobel(If_i, ddepth, 0, 1)\n",
    "\n",
    "    gradients.append(np.sqrt(dx**2+dy**2))\n",
    "gradients=np.stack(gradients,axis=0)\n",
    "\n",
    "multiRowPlot(\n",
    "    chain(If, gradients),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ | \\\\Delta I_{{ f{i} }} | $\")),\n",
    "    2,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3))\n",
    "markers = [cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel) for m in thresh]\n",
    "markers = [cv2.erode(m,  kernel) for m in markers]\n",
    "markers = np.stack(markers, axis=0)\n",
    "\n",
    "kernel = np.ones((5,5))\n",
    "bgs = [~cv2.dilate(m,  kernel, iterations=3) for m in thresh]\n",
    "bgs = np.stack(bgs, axis=0)\n",
    "\n",
    "plt_images = chain(thresh, markers, bgs)\n",
    "plt_titles = chain(imageTitles(\"thresh\"), imageTitles(\"marker\"), imageTitles(\"background\"))\n",
    "multiRowPlot(plt_images , plt_titles , 3, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = gradients*255/gradients.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import watershed\n",
    "\n",
    "watersheds=[]\n",
    "for m, bg, grad in zip(markers, bgs, gradients):\n",
    "    conn = 8\n",
    "    n_labels, labels =  cv2.connectedComponents(m, None, conn)\n",
    "\n",
    "    labels[bg>0] = labels.max() + 1\n",
    "    # plt.imshow(labels * 255 / labels.max())\n",
    "    out = watershed(grad, labels.astype(np.int32))\n",
    "    out[out==out.max()] = 0\n",
    "    watersheds.append(out)\n",
    "watersheds=np.stack(watersheds,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRowPlot(\n",
    "    chain(If, markers, watersheds),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$marker_{{ B{i} }}$\"), imageTitles(\"$watershed_{{ {i} }}$\")),\n",
    "    3,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ALL\n",
      "        count    mean     std  min  25%  50%     75%     max\n",
      "image1   58.0   95.16  223.55  1.0  1.0  1.0   24.75   990.0\n",
      "image2   34.0  244.29  350.60  1.0  1.0  4.0  583.75  1247.0\n",
      "image3   71.0  184.00  364.50  1.0  1.0  2.0   41.50  1821.0\n",
      "image4   36.0  211.69  327.19  1.0  1.0  1.0  501.75   980.0\n",
      "====== Areas > min_area=5\n",
      "        count    mean     std   min     25%    50%    75%     max\n",
      "image1   18.0  303.94  317.24   8.0   26.25  189.5  555.0   990.0\n",
      "image2   17.0  487.53  357.49   6.0   46.00  601.0  678.0  1247.0\n",
      "image3   27.0  481.59  457.49   7.0   23.00  591.0  736.5  1821.0\n",
      "image4   14.0  542.50  308.83  15.0  481.50  627.5  721.5   980.0\n",
      "====== watershed\n",
      "        count    mean     std    min     25%    50%     75%     max\n",
      "image1   16.0  332.38  291.47    4.0   40.75  324.0  580.25   933.0\n",
      "image2   14.0  538.29  267.64    5.0  518.00  575.5  594.00  1113.0\n",
      "image3   21.0  621.81  370.61    9.0  499.00  651.0  726.00  1680.0\n",
      "image4   12.0  651.75  146.55  409.0  565.75  645.0  702.75   964.0\n"
     ]
    }
   ],
   "source": [
    "print(\"====== ALL\")\n",
    "print_stats(areas)\n",
    "\n",
    "min_area=5\n",
    "print(f\"====== Areas > {min_area=}\")\n",
    "print_stats([a[a>min_area] for a in areas])\n",
    "print(f\"====== watershed\")\n",
    "get_areas_and_print_stats(255*(watersheds>0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered=[]\n",
    "for If_i in If:\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "    ddepth = cv2.CV_32F\n",
    "    \n",
    "    f = If_i\n",
    "    # f = cv2.medianBlur(f, ksize=7)\n",
    "\n",
    "    f = 255*(f > T)\n",
    "\n",
    "    f = cv2.morphologyEx(f.astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
    "    f = cv2.morphologyEx(f.astype(np.uint8), cv2.MORPH_OPEN, kernel)\n",
    "    # f = cv2.dilate(f.astype(np.uint8),  kernel, iterations=2)\n",
    "    filtered.append(f)\n",
    "    \n",
    "multiRowPlot(\n",
    "    chain(If, thresh, filtered),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ Thresh I_{{ f{i} }} $\"), imageTitles(\"$ Filter I_{{ f{i} }} $\")),\n",
    "    3,\n",
    "    N\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=[]\n",
    "for If_i in If:\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    # Set flags (Just to avoid line break in the code)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    # Apply KMeans\n",
    "    compactness,labels,centers = cv2.kmeans(\n",
    "            If_i.ravel().astype(np.float32),\n",
    "            2,\n",
    "            None,\n",
    "            criteria,\n",
    "            10,\n",
    "            flags\n",
    "        )\n",
    "\n",
    "    km = If_i.copy()\n",
    "    km.flat[labels.ravel()==0] = 0\n",
    "    km.flat[labels.ravel()==1] = 1\n",
    "\n",
    "    kmeans.append(km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRowPlot(\n",
    "    chain(If, kmeans, thresh),\n",
    "    chain(imageTitles(\"$ I_{{ f{i} }} $\"), imageTitles(\"$ KMeans ~I_{{ f{i} }} $\"), imageTitles(\"$ Thresh~I_{{ f{i} }} $\")),\n",
    "    3,\n",
    "    N\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51e85f04e04be4d88eed80c0e07765bbdfe0d9abe501b20be23dd8c1d7c4662d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
